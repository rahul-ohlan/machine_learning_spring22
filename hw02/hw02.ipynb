{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"hw2dataNorm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:,1:]\n",
    "# fullData=df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8815816 ,  1.04637137,  1.19253608, ..., -1.60292621,\n",
       "        -0.16195588,  1.        ],\n",
       "       [ 1.53868944,  1.7414904 , -2.0183408 , ...,  0.27748574,\n",
       "        -0.99310669,  1.        ],\n",
       "       [-0.08979522, -0.95209585,  0.89957286, ...,  0.38864925,\n",
       "        -1.55240038,  1.        ],\n",
       "       ...,\n",
       "       [ 0.25304366,  0.95948149, -0.2254059 , ...,  1.66492267,\n",
       "        -0.89728504,  0.        ],\n",
       "       [-1.68970996, -1.42999018,  1.23941019, ..., -0.29286325,\n",
       "         0.33915503,  0.        ],\n",
       "       [-1.28973128,  0.26436246, -0.11993914, ...,  0.89119704,\n",
       "         0.1618081 ,  1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = fullData[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fullData[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidLikelihood(X, y , w):\n",
    "    \n",
    "    rows,cols = X.shape\n",
    "    \n",
    "    dummy = np.ones(rows)\n",
    "    dummy = dummy.reshape((rows,1))\n",
    "    X1 = np.append(X,dummy,axis=1)\n",
    "    \n",
    "    def sigmoid(w_vector,xi):\n",
    "        return (1/(1+ np.exp(-(np.dot(w_vector,xi)))))\n",
    "    \n",
    "    def pseudo_probability(w,xi,yi):\n",
    "        return ((1-sigmoid(w,xi))**(1-yi))*((sigmoid(w,xi))**yi)\n",
    "    \n",
    "    vector = list()\n",
    "    for row in range(len(y)):\n",
    "        vector.append(pseudo_probability(w,X1[row,:],y[row]))\n",
    "        \n",
    "    return np.array(vector)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.05**248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.05**249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that, at 249 multipications of likelihoods, the resultant becomes 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.05]*249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-745.9373361149437"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans 2.b = -745.93733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume initial guesses for w vector incorporating the offset\n",
    "w = np.zeros(len(X[0])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_Likelihood(X, y, W):\n",
    "    \n",
    "    rows, cols = X.shape\n",
    "    \n",
    "    def sigmoid(w_vector,xi):\n",
    "        return (1/(1+ np.exp(-(np.sum(w_vector*xi)))))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def pseudo_probability(w_vector,xi,yi):\n",
    "        \n",
    "        yi = int(yi)\n",
    "        \n",
    "        f = (1 - sigmoid(w_vector,xi))**(1-yi)\n",
    "        s = (sigmoid(w_vector,xi))**yi\n",
    "        \n",
    "        res = f * s\n",
    "        return res\n",
    "    \n",
    "    \n",
    "    new_array = list()\n",
    "    \n",
    "    for i in range(rows):\n",
    "        new_array.append(pseudo_probability(W,X[i],y[i]))\n",
    "\n",
    "    new_array = np.array(new_array)\n",
    "    log_like = np.sum(np.log(new_array))  \n",
    "    return log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateRule(X, y, w):\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    def sigmoid(w_vector,xi):\n",
    "        sig =  (1/(1+ np.exp(-(np.dot(w_vector,xi)))))\n",
    "\n",
    "        return sig\n",
    "    \n",
    "    \n",
    "    rows, cols = X.shape\n",
    "    \n",
    "    # initialize gradient vector to all zeros\n",
    "    grad_vector = np.zeros(cols)\n",
    "    for i in range(rows):\n",
    "        \n",
    "        \n",
    "        for j in range(cols):\n",
    "            \n",
    "            xj = X[i][j]\n",
    "            yi = y[i]\n",
    "            \n",
    "            grad_vector[j] += xj*(yi - sigmoid(w,X[i])) # calculating gradients based on all of dataset\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(cols):        # this loop will be removed in the learnlogisticFast function\n",
    "        w[j] += learning_rate*grad_vector[j]\n",
    "\n",
    "        \n",
    "    return w\n",
    "\n",
    "\n",
    "\n",
    "def learnLogistic(w0, X, y, K):\n",
    "    \n",
    "    log_likelihood = list()\n",
    "    rows,cols = X.shape\n",
    "    \n",
    "    dummy = np.ones(rows)\n",
    "    dummy = dummy.reshape((rows,1))\n",
    "    X1 = np.append(X,dummy,axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for loop in range(K):\n",
    "    \n",
    "    \n",
    "        w0 = updateRule(X1, y, w0)\n",
    "        \n",
    "        log_likelihood.append(log_Likelihood(X1,y,w0))\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    return w0, np.array(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateRuleFast(X, y, w):\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    def sigmoid(w_vector,xi):\n",
    "        sig =  (1/(1+ np.exp(-(np.dot(w_vector,xi)))))\n",
    "\n",
    "        return sig\n",
    "    \n",
    "    \n",
    "    rows, cols = X.shape\n",
    "    \n",
    "    # initialize gradient vector to all zeros\n",
    "    grad_vector = np.zeros(cols) # reset updates\n",
    "    for i in range(rows):\n",
    "        \n",
    "        yi = y[i]\n",
    "            \n",
    "        grad_vector += X[i]*(yi - sigmoid(w,X[i])) # calculating gradients based on all of dataset\n",
    "            \n",
    "    \n",
    "    \n",
    "    # using Vectorization to update w skipping the for loop\n",
    "    \n",
    "    new_w = w + (learning_rate)*grad_vector\n",
    "    w = new_w\n",
    "            \n",
    "        \n",
    "    return w\n",
    "\n",
    "\n",
    "def learnLogisticFast(w0, X, y, K):\n",
    "    \n",
    "    log_likelihood = list()\n",
    "    rows,cols = X.shape\n",
    "    \n",
    "    dummy = np.ones(rows)\n",
    "    dummy = dummy.reshape((rows,1))\n",
    "    X1 = np.append(X,dummy,axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for loop in range(K):\n",
    "    \n",
    "    \n",
    "        w0 = updateRuleFast(X1, y, w0)\n",
    "        \n",
    "        log_likelihood.append(log_Likelihood(X1,y,w0))\n",
    "\n",
    "\n",
    "    return w0, np.array(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume initial guesses for w vector incorporating the offset\n",
    "w0 = np.zeros(len(X[0])+1)\n",
    "K = 10 # number of loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStart = time.time()\n",
    "w, LHistory = learnLogistic(w0, X, y, K)\n",
    "timeEnd = time.time()\n",
    "a = timeEnd-timeStart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.31582482 -0.21379867  0.66178671  0.44060446 -0.09422403  0.83404356\n",
      "  4.76143471 -1.12802087  1.15673754 -3.63355023  0.45697398]\n",
      "[-497.27729395 -463.3764476  -457.44326896 -453.55682843 -450.3679247\n",
      " -447.60265937 -445.19301184 -443.10375312 -441.30709101 -439.77603386]\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(LHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0268754959106445\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3693704605102539\n"
     ]
    }
   ],
   "source": [
    "timeStart = time.time()\n",
    "w1 = np.zeros(len(X[0])+1)\n",
    "wFast, LHistoryFast = learnLogisticFast(w1, X, y, K)\n",
    "timeEnd = time.time()\n",
    "b = timeEnd-timeStart\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.31582482 -0.21379867  0.66178671  0.44060446 -0.09422403  0.83404356\n",
      "  4.76143471 -1.12802087  1.15673754 -3.63355023  0.45697398]\n",
      "[-497.27729395 -463.3764476  -457.44326896 -453.55682843 -450.3679247\n",
      " -447.60265937 -445.19301184 -443.10375312 -441.30709101 -439.77603386]\n"
     ]
    }
   ],
   "source": [
    "print(wFast)\n",
    "print(LHistoryFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6575050354003906\n"
     ]
    }
   ],
   "source": [
    "print(a-b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticClassify(X, w):\n",
    "    \n",
    "    rows,cols = X.shape\n",
    "    \n",
    "    dummy = np.ones(rows)\n",
    "    dummy = dummy.reshape((rows,1))\n",
    "    X1 = np.append(X,dummy,axis=1)\n",
    "    \n",
    "    classLabels = list()\n",
    "    for i in range(rows):\n",
    "        \n",
    "        if np.dot(w,X1[i]) > 0:\n",
    "            classLabels.append(1)\n",
    "        else:\n",
    "            classLabels.append(0)\n",
    "            \n",
    "    return np.array(classLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = logisticClassify(X,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,d = 0,0\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 0 and labels[i] == 0:\n",
    "        c+=1\n",
    "\n",
    "    elif y[i] == 1 and labels[i] == 1:\n",
    "        d +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903 994\n"
     ]
    }
   ],
   "source": [
    "print(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9485\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ',(c+d)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
